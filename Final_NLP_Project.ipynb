{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A3DjprMyYc0",
        "outputId": "e66fc1f9-b678-4ee7-bbe2-3602be374f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample cleaned lines:\n",
            "- They do not!\n",
            "- They do to!\n",
            "- I hope so.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n",
        "\n",
        "# Load and clean movie line dataset\n",
        "def load_movie_lines(path):\n",
        "    lines = []\n",
        "    with open(path, encoding='ISO-8859-1') as file:  # ‚Üê FIXED ENCODING\n",
        "        for line in file:\n",
        "            parts = line.strip().split(\"+++$+++\")\n",
        "            if len(parts) == 5:\n",
        "                sentence = parts[4].strip()\n",
        "                if sentence:\n",
        "                    lines.append(sentence)\n",
        "    return lines\n",
        "\n",
        "# dataset file\n",
        "file_path = \"/content/movie_lines.txt\"\n",
        "corpus = load_movie_lines(file_path)\n",
        "\n",
        "# Preview 3 cleaned lines\n",
        "print(\"Sample cleaned lines:\")\n",
        "for i in range(3):\n",
        "    print(\"-\", corpus[i])\n",
        "\n",
        "# Function to predict next words using BERT\n",
        "def predict_next_words(seed_text, top_k=5):\n",
        "    seed_text = seed_text.strip()\n",
        "    if not seed_text.endswith(\" \"):\n",
        "        seed_text += \" \"\n",
        "    input_text = seed_text + \"[MASK]\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    mask_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    mask_word_logits = logits[0, mask_index, :]\n",
        "    sorted_indices = torch.argsort(mask_word_logits, dim=-1, descending=True)[0]\n",
        "\n",
        "    predictions = []\n",
        "    for idx in sorted_indices:\n",
        "        word = tokenizer.decode([idx]).strip()\n",
        "        # Skip punctuation\n",
        "        if word.isalpha():\n",
        "            predictions.append(word)\n",
        "        if len(predictions) == top_k:\n",
        "            break\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Test it\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter a 3+ word phrase (or 'exit'): \").strip()\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    if len(user_input.split()) < 3:\n",
        "        print(\"‚ö†Ô∏è Please enter at least 3 words.\")\n",
        "        continue\n",
        "    preds = predict_next_words(user_input)\n",
        "    print(\"üîÆ Top prediction:\", preds[0])\n",
        "    print(\"üß† Top 5 predictions:\", preds)"
      ],
      "metadata": {
        "id": "YB2PzcpWyfKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f657c176-6e05-4cc7-f8f1-fd413a4d4df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a 3+ word phrase (or 'exit'): my name is choco \n",
            "üîÆ Top prediction: and\n",
            "üß† Top 5 predictions: ['and', 'so', 'here', 'because', 'you']\n",
            "\n",
            "Enter a 3+ word phrase (or 'exit'): i hate\n",
            "‚ö†Ô∏è Please enter at least 3 words.\n",
            "\n",
            "Enter a 3+ word phrase (or 'exit'): i don't like\n",
            "üîÆ Top prediction: it\n",
            "üß† Top 5 predictions: ['it', 'you', 'and', 'that', 'me']\n",
            "\n",
            "Enter a 3+ word phrase (or 'exit'): i love you but not \n",
            "üîÆ Top prediction: you\n",
            "üß† Top 5 predictions: ['you', 'me', 'because', 'god', 'so']\n",
            "\n",
            "Enter a 3+ word phrase (or 'exit'): i am currently in BSAI\n",
            "üîÆ Top prediction: and\n",
            "üß† Top 5 predictions: ['and', 'because', 'today', 'so', 'where']\n",
            "\n",
            "Enter a 3+ word phrase (or 'exit'): my CGPA is 2.89 but i will\n",
            "üîÆ Top prediction: take\n",
            "üß† Top 5 predictions: ['take', 'be', 'work', 'go', 'do']\n"
          ]
        }
      ]
    }
  ]
}